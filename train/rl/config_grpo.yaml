data:
  train_files: hiyouga/math12k@train
  val_files: hiyouga/math12k@test
  prompt_key: question
  answer_key: answer
  image_key: image_path
  max_prompt_length: 5120
  max_response_length: 16384            # last: 16384, 8192
  rollout_batch_size: 32                  #  origin: 512
  val_batch_size: 16                       # -1, batch_size=len(self.val_dataset) if self.config.data.val_batch_size == -1 else self.config.data.val_batch_size,
  shuffle: true
  seed: 1
  max_pixels: 200704                  # 256*28*28=448*448=200704; 512*28*28 = 633*633; origin: 4194304
  min_pixels: 16384                        # 262144

  
algorithm:
  adv_estimator: grpo
  disable_kl: false     # apply kl to reward
  use_kl_loss: true     # apply kl to loss
  kl_penalty: low_var_kl
  kl_coef: 1.0e-2

worker:
  actor:
    global_batch_size: 16                                    # 128
    micro_batch_size_per_device_for_update: 1                  # origin: 4; 4 or 8 or 16
    micro_batch_size_per_device_for_experience: 1              #  16
    max_grad_norm: 1.0
    padding_free: true
    ulysses_sequence_parallel_size: 1
    model:
      model_path: Qwen/Qwen2.5-7B-Instruct
      enable_gradient_checkpointing: true
      trust_remote_code: false
      freeze_vision_tower: false
    optim:
      lr: 1.0e-6
      weight_decay: 1.0e-2
      strategy: adamw  # {adamw, adamw_bf16}
      lr_warmup_ratio: 0.0
    fsdp:
      enable_full_shard: true
      enable_cpu_offload: false
      enable_rank0_init: true
    offload:
      offload_params: false  # true: more CPU memory; false: more GPU memory
      offload_optimizer: false  # true: more CPU memory; false: more GPU memory

  rollout:
    temperature: 1.0
    n: 8                                # origin: 5
    gpu_memory_utilization: 0.60      # origin: 0.60
    enforce_eager: false
    enable_chunked_prefill: false
    tensor_parallel_size: 2
    limit_images: 0
    val_override_config:
      temperature: 0.5
      n: 1
    max_num_batched_tokens: 32768       # > model_len last 20480, 16384
    # prompt_length
    # response_length
    single_turn_response_length: 1024

  ref:
    fsdp:
      enable_full_shard: true
      enable_cpu_offload: false  # true: more CPU memory; false: more GPU memory
      enable_rank0_init: true
    offload:
      offload_params: false

  reward:
    reward_type: function
    compute_score: gcot # math

trainer:
  total_episodes: 1                             # origin 15
  logger: ["console", "tensorboard"]
  project_name: easy_r1
  experiment_name: easy_r1
  n_gpus_per_node: 8
  nnodes: 1
  val_freq: -1             # origin:5; -1 to disable
  val_before_train: false
  val_only: false
  val_generations_to_log: 1
  save_freq: 50            # origin 5; -1 to disable
  save_limit: 3           # -1 to disable
  save_checkpoint_path: null
  load_checkpoint_path: null
